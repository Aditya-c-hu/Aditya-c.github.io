
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithm Reflections</title>
    <style>
        body {
            font-family: 'Product Sans', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #e6f7ff;
            color: #333;
        }
        h1 {
            text-align: center;
            color: white;
            background-color: #004080;
            padding: 20px;
        }
        h2 {
            color: #004080;
        }
        section {
            margin-bottom: 20px;
            padding: 15px;
            background: #ffffff;
            border-radius: 8px;
        }
        p {
            margin: 0 0 10px;
        }
        .button-container {
            text-align: center;
            margin-top: 20px;
        }
        .button-container a {
            display: inline-block;
            padding: 10px 20px;
            text-decoration: none;
            background-color: #004080;
            color: white;
            border-radius: 5px;
            font-weight: bold;
            transition: background-color 0.3s ease; 
            margin-bottom: 10px;
        }
        .button-container a:hover {
            background-color: #0059b3;
        }
    </style>
</head>
<body>

    <h1>Reflections</h1>

    <section>
        <h2>What are the kinds of problems we see in nature?</h2>
        <p>Nature presents a variety of challenges that require creative solutions. Some problems, like the changing seasons, follow repetitive patterns and are best addressed through iterative methods. Others, such as the branching of trees or the formation of snowflakes, involve self-similar patterns that can be solved using recursion. More complex problems, like an ant navigating a maze, require a trial-and-error approach similar to backtracking. These methods—iteration, recursion, and backtracking—reflect nature's strategies for finding effective solutions.</p>
    </section>

    <section>
        <h2>What is space and time efficiency? Why are they important?</h2>
        <p>Space efficiency refers to the amount of memory a program uses, while time efficiency measures how quickly it runs. Both are essential because resources like memory and time are limited. Imagine an app that crashes your phone due to excessive memory usage or a program that takes hours to complete simple tasks—it wouldn't be practical or effective. Efficiency ensures that software runs smoothly, even as data volumes grow or devices become smaller with less capacity.</p>
    </section>

    <section>
        <h2>Takeaway from different design principles from Chapter 2</h2>
        <p>Chapter 2 emphasized the importance of breaking down problems and solving them systematically. Modular design involves dividing problems into smaller parts, making them easier to tackle and debug. The divide-and-conquer approach, like in merge sort, involves breaking problems into halves, solving each part, and combining the results to save time. Optimization, especially through techniques like dynamic programming, showed that small improvements can significantly enhance efficiency..</p>
    </section>

    <section>
        <h2>The hierarchical data and how different tree data structures solve problems</h2>
        <p>Hierarchical data is prevalent in file systems, organization charts, and game levels. Trees are ideal for managing this type of data. Binary search trees are excellent for quick searching and sorting. AVL trees and red-black trees maintain balance, ensuring consistent operations even with uneven data. Heaps are invaluable for managing priorities, such as scheduling tasks. These structures are not just theoretical concepts—they solve real-world problems efficiently.</p>
    </section>

    <section>
        <h2>The need for array query algorithms and their implications</h2>
        <p>Handling large datasets efficiently requires array query algorithms. For instance, segment trees facilitate range-based queries like summing numbers in a range or finding a maximum. Fenwick trees enable fast updates while keeping data organized. These tools make managing large amounts of data more efficient, especially in applications like databases and coding competitions.</p>
    </section>

    <section>
        <h2>Differentiate between trees and graphs and their traversals</h2>
        <p>Trees and graphs both deal with nodes and connections, but they’re used for different purposes. Trees are like organized family trees—everything follows a hierarchy, and there’s only one way to connect any two nodes. Graphs are messier, like a web, with connections going anywhere. Traversals like DFS and BFS help explore these structures, whether it’s for hierarchical trees or networks like maps and social media connections.</p>
    </section>

    <section>
        <h2>Deliberate on sorting and searching algorithms</h2>
        <p>Sorting and searching are the backbone of efficient data handling. Sorting makes things easier to find or use later, like alphabetizing a list of contacts. Algorithms like quicksort and merge sort ensure this is done in a smart way. Searching, on the other hand, helps pinpoint what you need—binary search is super fast but needs sorted data, while linear search works everywhere but can be slow. Together, they keep data accessible and usable.</p>
    </section>

    <section>
        <h2>The importance of graph algorithms</h2>
        <p>Graph algorithms are essential for solving real-world problems, like finding the shortest route on Google Maps. They optimize connections in transportation, communication, or social networks. Algorithms like Dijkstra’s for shortest paths or Kruskal’s for building efficient networks are practical tools that directly impact areas like logistics and network design. They’re fascinating because they mirror real challenges we face daily.</p>
    </section>

    <section>
        <h2>Different studied algorithm design techniques</h2>
        <p>TThe different design techniques we learned—like greedy algorithms, dynamic programming, and divide-and-conquer—all stood out for how systematic they are. Greedy algorithms are like quick decisions that work for problems like building an efficient file compression. Dynamic programming is about carefully building on smaller solutions, like solving puzzles one piece at a time. Divide-and-conquer, meanwhile, felt like breaking a big task into manageable parts—something we do in everyday life, like organizing a big project. These approaches make solving complex problems a lot simpler.</p>
    </section>

</body>
</html>

